# ğŸ™ï¸ Emotion Recognition from Voice using Machine Learning

## ğŸ˜ƒğŸ”Š Project Overview

This project is a Machine Learning-based system that detects **emotions from raw human voice recordings** â€” without relying on speech-to-text. By analyzing **acoustic features** such as pitch, MFCCs, tone, and spectrograms, the model classifies speech into emotional states like *happy, sad, angry, neutral*, and more.

> âš¡ Built to be **language-independent**, this system is ideal for real-time applications in **mental health monitoring**, **empathetic voice assistants**, and **customer service analytics**.

---

## ğŸš€ Key Features

- ğŸ§ **Audio-only Emotion Detection** (No transcription needed)
- ğŸ“Š Feature extraction: **MFCCs, Chroma, Spectral Contrast, Tonnetz**
- ğŸ§  Trained on multilingual emotional speech datasets
- ğŸŒ Language-agnostic design
- ğŸ“ˆ Supports real-time and batch predictions
- ğŸ§ª Includes test data and visualization scripts

---

## ğŸ“ Project Structure

